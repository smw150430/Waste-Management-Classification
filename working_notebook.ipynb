{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG19\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip data/hot-dog-not-hot-dog.zip -d data/ # sample code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data and Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2513 images belonging to 2 classes.\n",
      "Found 22564 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_te = ImageDataGenerator(rescale = 1./255).flow_from_directory('DATASET/TEST', \n",
    "                                                                   target_size = (224, 224), \n",
    "                                                                   batch_size = 2513,\n",
    "                                                                   seed = 123)\n",
    "\n",
    "data_tr = ImageDataGenerator(rescale = 1./255).flow_from_directory('DATASET/TRAIN', \n",
    "                                                                   target_size = (224, 224),  \n",
    "                                                                   batch_size = 22564,\n",
    "                                                                   seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2513 images belonging to 2 classes.\n",
      "Found 22564 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "mod_te = ImageDataGenerator(rescale = 1./255, \n",
    "                            rotation_range = 360, \n",
    "                            width_shift_range = 0.3, \n",
    "                            height_shift_range = 0.3, \n",
    "                            brightness_range = [0.2, 1.0], \n",
    "                            horizontal_flip = True, \n",
    "                            vertical_flip = True, \n",
    "                            zoom_range = [0.5, 1.5]).flow_from_directory('DATASET/TEST', \n",
    "                                                                   target_size = (224, 224), \n",
    "                                                                   batch_size = 625,\n",
    "                                                                   seed = 123)\n",
    "\n",
    "mod_tr = ImageDataGenerator(rescale = 1./255, \n",
    "                            rotation_range = 360, \n",
    "                            width_shift_range = 0.3, \n",
    "                            height_shift_range = 0.3, \n",
    "                            brightness_range = [0.2, 1.0], \n",
    "                            horizontal_flip = True, \n",
    "                            vertical_flip = True, \n",
    "                            zoom_range = [0.5, 1.5]).flow_from_directory('DATASET/TRAIN', \n",
    "                                                                   target_size = (224, 224), \n",
    "                                                                   batch_size = 1000,\n",
    "                                                                   seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_te, labels_te = next(data_te)\n",
    "images_tr, labels_tr = next(data_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_mod_te, labels_mod_te = next(mod_te)\n",
    "images_mod_tr, labels_mod_tr = next(mod_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2513, 224, 224, 3)\n",
      "(22564, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images_te.shape)\n",
    "print(images_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625, 224, 224, 3)\n",
      "(1000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images_mod_te.shape)\n",
    "print(images_mod_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2513, 2)\n",
      "(22564, 2)\n"
     ]
    }
   ],
   "source": [
    "print(labels_te.shape)\n",
    "print(labels_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625, 2)\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(labels_mod_te.shape)\n",
    "print(labels_mod_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.concatenate((images_tr, images_te, images_mod_tr, images_mod_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26702, 224, 224, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate((labels_tr[:,0], labels_te[:,0], labels_mod_tr[:,0], labels_mod_te[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26702,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model, X_test, y_model, y_test = train_test_split(images, labels, test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_model, y_model, test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building CNN Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_vgg_base = VGG19(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "model_1 = models.Sequential()\n",
    "model_1.add(cnn_vgg_base)\n",
    "model_1.add(layers.Flatten())\n",
    "model_1.add(layers.Dense(1024, activation='relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "model_1.add(layers.Dense(1024, activation='relu', kernel_regularizer = regularizers.l2(0.01)))  \n",
    "model_1.add(layers.Dense(512, activation='relu', kernel_regularizer = regularizers.l2(0.01)))  \n",
    "model_1.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19 True\n",
      "flatten_1 True\n",
      "dense_1 True\n",
      "dense_2 True\n",
      "dense_3 True\n",
      "dense_4 True\n"
     ]
    }
   ],
   "source": [
    "for layer in model_1.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_vgg_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19 False\n",
      "flatten_1 True\n",
      "dense_1 True\n",
      "dense_2 True\n",
      "dense_3 True\n",
      "dense_4 True\n"
     ]
    }
   ],
   "source": [
    "for layer in model_1.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss = 'binary_crossentropy', optimizer = optimizers.Adam(), metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13083 samples, validate on 5608 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_1.fit(X_train, \n",
    "                                y_train, \n",
    "                                batch_size = 200, \n",
    "                                epochs = 10, \n",
    "                                validation_data = (X_val, y_val), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
