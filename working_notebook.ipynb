{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG19, inception_v3\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip data/hot-dog-not-hot-dog.zip -d data/ # sample code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data and Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2513 images belonging to 2 classes.\n",
      "Found 22564 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_te = ImageDataGenerator(rescale = 1./255).flow_from_directory('DATASET/TEST', \n",
    "                                                                   target_size = (224, 224), \n",
    "                                                                   batch_size = 2513,\n",
    "                                                                   seed = 123)\n",
    "\n",
    "data_tr = ImageDataGenerator(rescale = 1./255).flow_from_directory('DATASET/TRAIN', \n",
    "                                                                   target_size = (224, 224),  \n",
    "                                                                   batch_size = 22564,\n",
    "                                                                   seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2513 images belonging to 2 classes.\n",
      "Found 22564 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "mod_te = ImageDataGenerator(rescale = 1./255, \n",
    "                            rotation_range = 360, \n",
    "                            width_shift_range = 0.3, \n",
    "                            height_shift_range = 0.3, \n",
    "                            brightness_range = [0.2, 1.0], \n",
    "                            horizontal_flip = True, \n",
    "                            vertical_flip = True, \n",
    "                            zoom_range = [0.5, 1.5]).flow_from_directory('DATASET/TEST', \n",
    "                                                                   target_size = (224, 224), \n",
    "                                                                   batch_size = 1000,\n",
    "                                                                   seed = 123)\n",
    "\n",
    "mod_tr = ImageDataGenerator(rescale = 1./255, \n",
    "                            rotation_range = 360, \n",
    "                            width_shift_range = 0.3, \n",
    "                            height_shift_range = 0.3, \n",
    "                            brightness_range = [0.2, 1.0], \n",
    "                            horizontal_flip = True, \n",
    "                            vertical_flip = True, \n",
    "                            zoom_range = [0.5, 1.5]).flow_from_directory('DATASET/TRAIN', \n",
    "                                                                   target_size = (224, 224), \n",
    "                                                                   batch_size = 5000,\n",
    "                                                                   seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_te, labels_te = next(data_te)\n",
    "images_tr, labels_tr = next(data_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_mod_te, labels_mod_te = next(mod_te)\n",
    "images_mod_tr, labels_mod_tr = next(mod_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2513, 224, 224, 3)\n",
      "(22564, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images_te.shape)\n",
    "print(images_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64, 3)\n",
      "(32, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images_mod_te.shape)\n",
    "print(images_mod_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2513, 2)\n",
      "(22564, 2)\n"
     ]
    }
   ],
   "source": [
    "print(labels_te.shape)\n",
    "print(labels_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625, 2)\n",
      "(1575, 2)\n"
     ]
    }
   ],
   "source": [
    "print(labels_mod_te.shape)\n",
    "print(labels_mod_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.concatenate((images_tr, images_te, images_mod_tr, images_mod_te))\n",
    "# images = np.concatenate((images_mod_tr, images_mod_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate((labels_tr[:,0], labels_te[:,0], labels_mod_tr[:,0], labels_mod_te[:, 0]))\n",
    "# labels = np.concatenate((labels_mod_tr[:,0], labels_mod_te[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[2])\n",
    "plt.show()\n",
    "print(labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model, X_test, y_model, y_test = train_test_split(images, labels, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_model, y_model, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408 \n",
      "\n",
      "352 \n",
      "\n",
      "440 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), '\\n')\n",
    "print(len(X_val), '\\n')\n",
    "print(len(X_test), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5355113636363636\n",
      "0.5568181818181818\n",
      "0.55\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_train)/1408)\n",
    "print(sum(y_val)/352)\n",
    "print(sum(y_test)/440)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building CNN Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_vgg_base = VGG19(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "model_1 = models.Sequential()\n",
    "model_1.add(cnn_vgg_base)\n",
    "model_1.add(layers.Flatten())\n",
    "model_1.add(layers.Dense(1024, activation='relu', kernel_initializer = 'glorot_uniform'))\n",
    "model_1.add(layers.Dropout(0.2, seed = 123))\n",
    "model_1.add(layers.Dense(1024, activation='relu', kernel_initializer = 'glorot_uniform'))\n",
    "model_1.add(layers.Dropout(0.2, seed = 123))\n",
    "model_1.add(layers.Dense(512, activation='relu', kernel_initializer = 'glorot_uniform'))\n",
    "model_1.add(layers.Dropout(0.2, seed = 123))\n",
    "model_1.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19 True\n",
      "flatten_1 True\n",
      "dense_1 True\n",
      "dense_2 True\n",
      "dense_3 True\n",
      "dense_4 True\n"
     ]
    }
   ],
   "source": [
    "for layer in model_1.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_vgg_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19 False\n",
      "flatten_1 True\n",
      "dense_1 True\n",
      "dense_2 True\n",
      "dense_3 True\n",
      "dense_4 True\n"
     ]
    }
   ],
   "source": [
    "for layer in model_1.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss = 'binary_crossentropy', optimizer = optimizers.Adam(), metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.fit(X_train, \n",
    "            y_train, \n",
    "            batch_size = 16, \n",
    "            epochs = 100, \n",
    "            validation_data = (X_val, y_val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('vgg19.h5')\n",
    "# models.load_model('vgg19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_1_pred = np.around(model_1.predict(X_test))\n",
    "mod_1_test_pred = model_1.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, mod_1_test_pred))\n",
    "print(classification_report(y_test, mod_1_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yellowbrick doesn't work with keras; change class labels; see if this works\n",
    "con_mat_1 = tf.math.confusion_matrix(labels=y_test, predictions=mod_1_test_pred).numpy()\n",
    "con_mat_1_df = pd.DataFrame(con_mat_1,\n",
    "                     index = classes, \n",
    "                     columns = classes)\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_1_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "# plt.savefig('vgg19_conf_mat.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_incv3_base = inception_v3.InceptionV3(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(cnn_incv3_base)\n",
    "model_2.add(layers.Flatten())\n",
    "model_2.add(layers.Dropout(0.2, seed = 123))\n",
    "model_2.add(layers.Dense(1024, activation='relu', kernel_initializer = 'glorot_uniform'))\n",
    "model_2.add(layers.Dropout(0.2, seed = 123))\n",
    "model_2.add(layers.Dense(512, activation='relu', kernel_initializer = 'glorot_uniform'))\n",
    "model_2.add(layers.Dropout(0.2, seed = 123))\n",
    "model_2.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_incv3_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss = 'binary_crossentropy', optimizer = optimizers.Adam(), metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.fit(X_train, \n",
    "            y_train, \n",
    "            batch_size = 16, \n",
    "            epochs = 100, \n",
    "            validation_data = (X_val, y_val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save('incv3.h5')\n",
    "# models.load_model('incv3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_2_pred = np.around(model_2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, mod_2_pred))\n",
    "print(classification_report(y_test, mod_2_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
